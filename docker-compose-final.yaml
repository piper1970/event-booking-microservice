volumes:
  postgres-data:
    name: "event-service-postgres-volume"
  prometheus-data:
    name: "event-service-prometheus-data"
  grafana-data:
    name: "event-service-grafana-data"
#  pgadmin-data:
#    name: "event-service-pgadmin-volume"

services:

  ### Project-Based Services ###

  discovery-server:
    build: ./discovery-server
    ports:
      - "8089:8089"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8089/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  event-service-config:
    build: ./event-service-config
    ports:
      - "8888:8888"
    environment:
      SPRING_PROFILES_ACTIVE: native,local_discovery
      SPRING_CLOUD_CONFIG_SERVER_NATIVE_SEARCH-LOCATIONS: file:/var/config,file:/var/config/{application},file:/var/config/{application}/{profile}
    depends_on:
      discovery-server:
        condition: service_healthy
    volumes:
      - ./data/config:/var/config

  event-service-gateway:
    build: ./event-service-gateway
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE: local_discovery
      OAUTH2_PROVIDER_BASE-URI: http://keycloak:9090/realms/piper1970
    depends_on:
      discovery-server:
        condition: service_healthy
      event-service-config:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  booking-service:
    build: ./booking-service
    ports:
      - "8083:8083"
    environment:
      SPRING_PROFILES_ACTIVE: local_discovery
      BOOKINGS_DB_HOST: postgres
      OAUTH2_ISSUER_URI: http://keycloak:9090/realms/piper1970
      SPRING_CLOUD_CONFIG_URI: http://event-service-config:8888
      SPRING_CONFIG_IMPORT: optional:configserver:http://event-service-config:8888
      DISCOVERY-SERVER_HOST: discovery-server
    depends_on:
      postgres:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
      event-service-config:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  event-service:
    build: ./event-service
    ports:
      - "8081:8081"
    environment:
      SPRING_PROFILES_ACTIVE: local_discovery
      EVENTS_DB_HOST: postgres
      OAUTH2_ISSUER_URI: http://keycloak:9090/realms/piper1970
      SPRING_CLOUD_CONFIG_URI: http://event-service-config:8888
      SPRING_CONFIG_IMPORT: optional:configserver:http://event-service-config:8888
      DISCOVERY-SERVER_HOST: discovery-server
    depends_on:
      postgres:
        condition: service_healthy
      discovery-server:
        condition: service_healthy
      event-service-config:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  # TODO: needs environment variables setup, if any
  payment-service:
    build: ./payment-service
    ports:
      - "8082:8082"
    environment:
      PAYMENTS_DB.HOST: postgres:5432
    depends_on:
      postgres:
        condition: service_healthy
      event-service-config:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  # TODO: setup environment variables, if needed
  notification-service:
    build: ./notification-service
    ports:
      - "8084:8084"
    depends_on:
      postgres:
        condition: service_healthy
      event-service-config:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8084/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  ### External Services ###

  # Database Engine
  postgres:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./data/scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5

#  # GUI-Based Access To Postgres Database Engine
#  pgadmin4:
#    image: elestio/pgadmin:latest
#    restart: always
#    ports:
#      - "1500:8080"
#    volumes:
#      - ./data/pgadmin/servers.json:/pgadmin4/servers.json
#      - pgadmin-data:/var/lib/pgadmin
#    environment:
#      PGADMIN_LISTEN_PORT: 8080
#      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
#      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL}
#    depends_on:
#      - postgres

  # Tracing for Logs across microservices
  zipkin:
    image: openzipkin/zipkin:3
    restart: always
    shm_size: 128mb
    ports:
      - "9411:9411"
    healthcheck:
      test: ["CMD", "docker-healthcheck"]
      interval: 5s
      timeout: 5s
      retries: 20

  # OAuth2/OpenId Authentication/Authorization Services
  keycloak:
    image: keycloak/keycloak:26.1
    container_name: piper-keycloak.openid-provider
    ports:
      - "9090:8080"
    environment:
      KC_DB: postgres
      KC_DB_USERNAME: ${KC_DB_USERNAME}
      KC_DB_PASSWORD: ${KC_DB_PASSWORD}
      KC_DB_URL_HOST: postgres
      KC_DB_URL_DATABASE: keycloak
      KEYCLOAK_ADMIN: ${KC_ADMIN_USER}
      KEYCLOAK_ADMIN_PASSWORD: ${KC_ADMIN_PASSWORD}
      KC_HTTP_PORT: 8080
      KC_HTTP_RELATIVE_PATH: /
      KC_HTTP_ENABLED: true
      KC_HEALTH_ENABLED: true
      KC_METRICS_ENABLED: true
    volumes:
      - ./data/keycloak/:/opt/keycloak/data/import/
    command:
      - start-dev
      - --import-realm
    healthcheck:
      test: ['CMD-SHELL', '[ -f /tmp/HealthCheck.java ] || echo "public class HealthCheck { public static void main(String[] args) throws java.lang.Throwable { System.exit(java.net.HttpURLConnection.HTTP_OK == ((java.net.HttpURLConnection)new java.net.URL(args[0]).openConnection()).getResponseCode() ? 0 : 1); } }" > /tmp/HealthCheck.java && java /tmp/HealthCheck.java http://localhost:8080/auth/health/live']
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy

  # Cluster Management For Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.9.0
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "2181" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Event-Based Messaging Bridge
  kafka:
    image: confluentinc/cp-kafka:7.9.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list" ]
      interval: 30s
      timeout: 10s
      retries: 5

  # Initialization Script to set up topics for kafka
  kafka-init:
    image: confluentinc/cp-kafka:7.0.0
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
        echo 'Creating Kafka topics...'
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic create-booking --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic create-booking-success --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic create-booking-failed --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic cancel-booking --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic refund-problems --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic event-changed --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic booking-updates --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic event-cancelled --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic booking-cancelled --partitions 3 --replication-factor 1
        echo 'Topics created.'
      "

  # Mocked External Payments API - interacts with payment-service
  # TODO: setup health check
  # TODO: need to setup templates within ./data/mock-payment-api folder. Are config files needed??
  mock-payment-api:
    image: wiremock/wiremock:2.35.0
    ports:
      - "9000:9000"
    volumes:
      - ./data/mock-payment-api:/home/wiremock
    command: ["--global-response-templating"]

  # Monitoring
  # TODO: need to fill out ./data/config/prometheus/prometheus.yml
  prometheus:
    image: prom/prometheus:v2.42.0
    ports:
      - "9090:9090"
    volumes:
      - ./data/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    healthcheck:
      test: ["CMD", "wget", "http://localhost:9090"]
      interval: 10s
      timeout: 15s
      retries: 10
      start_period: 40s

  # Visual Display for Monitoring
  # TODO: are config files needed in the ./data/grafana/provisioning folder??
  grafana:
    image: grafana/grafana:9.4.3
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./data/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
